{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class CropLayer(object):\n",
    "    def __init__(self, params, blobs):\n",
    "        # initialize our starting and ending (x, y)-coordinates of\n",
    "        # the crop\n",
    "        self.startX = 0\n",
    "        self.startY = 0\n",
    "        self.endX = 0\n",
    "        self.endY = 0\n",
    "\n",
    "    def getMemoryShapes(self, inputs):\n",
    "        # the crop layer will receive two inputs -- we need to crop\n",
    "        # the first input blob to match the shape of the second one,\n",
    "        # keeping the batch size and number of channels\n",
    "        (inputShape, targetShape) = (inputs[0], inputs[1])\n",
    "        (batchSize, numChannels) = (inputShape[0], inputShape[1])\n",
    "        (H, W) = (targetShape[2], targetShape[3])\n",
    "\n",
    "        # compute the starting and ending crop coordinates\n",
    "        self.startX = int((inputShape[3] - targetShape[3]) / 2)\n",
    "        self.startY = int((inputShape[2] - targetShape[2]) / 2)\n",
    "        self.endX = self.startX + W\n",
    "        self.endY = self.startY + H\n",
    "\n",
    "        # return the shape of the volume (we'll perform the actual\n",
    "        # crop during the forward pass\n",
    "        return [[batchSize, numChannels, H, W]]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # use the derived (x, y)-coordinates to perform the crop\n",
    "        return [inputs[0][:, :, self.startY:self.endY,\n",
    "                self.startX:self.endX]]\n",
    "\n",
    "\n",
    "# The pre-trained model that OpenCV uses has been trained in Caffe framework\n",
    "#Download from the link above\n",
    "protoPath = r\"/kaggle/input/dronecpp/deploy.prototxt\"\n",
    "modelPath = r\"/kaggle/input/dronecpp/hed_pretrained_bsds.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "# register our crop layer with the model\n",
    "cv2.dnn_registerLayer(\"Crop\", CropLayer)\n",
    "\n",
    "# Print out the architecture of the model\n",
    "def print_model_architecture(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    for i, name in enumerate(layer_names):\n",
    "        layer_id = net.getLayerId(name)\n",
    "        print(f\"Layer {i + 1}: {name} (ID: {layer_id})\")\n",
    "\n",
    "print_model_architecture(net)\n",
    "\n",
    "# load the input image and grab its dimensions, for future use while defining the blob\n",
    "img = cv2.imread(r\"/kaggle/input/dronecpp/worldview-2-rakaia-river.jpg\")\n",
    "(H, W) = img.shape[:2]\n",
    "\n",
    "# construct a blob out of the input image \n",
    "#blob is basically preprocessed image. \n",
    "#OpenCVâ€™s new deep neural network (dnn ) module contains two functions that \n",
    "#can be used for preprocessing images and preparing them for \n",
    "#classification via pre-trained deep learning models.\n",
    "# It includes scaling and mean subtraction\n",
    "#How to calculate the mean?\n",
    "mean_pixel_values= np.average(img, axis = (0,1))\n",
    "blob = cv2.dnn.blobFromImage(img, scalefactor=0.7, size=(W, H),\n",
    "                             #mean=(mean_pixel_values[0], mean_pixel_values[1], mean_pixel_values[2]),\n",
    "                             mean=(110, 125, 150),\n",
    "                             swapRB= False, crop=False)\n",
    "\n",
    "#View image after preprocessing (blob)\n",
    "blob_for_plot = np.moveaxis(blob[0,:,:,:], 0,2)\n",
    "plt.imshow(blob_for_plot)\n",
    "\n",
    "\n",
    "# set the blob as the input to the network and perform a forward pass\n",
    "# to compute the edges\n",
    "net.setInput(blob)\n",
    "hed = net.forward()\n",
    "hed = hed[0,0,:,:]  #Drop the other axes \n",
    "#hed = cv2.resize(hed[0, 0], (W, H))\n",
    "hed = (255 * hed).astype(\"uint8\")  #rescale to 0-255\n",
    "\n",
    "plt.imshow(hed, cmap='gray')\n",
    "\n",
    "####################\n",
    "#Connected component based labeling\n",
    "\n",
    "# Load segmented binary image, Gaussian blur, grayscale, Otsu's threshold\n",
    "blur = cv2.GaussianBlur(hed, (3,3), 0)\n",
    "\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "plt.imshow(thresh)\n",
    "\n",
    "# Perform connected component labeling\n",
    "n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresh, connectivity=4)\n",
    "\n",
    "# Create false color image with black background and colored objects\n",
    "colors = np.random.randint(0, 255, size=(n_labels, 3), dtype=np.uint8)\n",
    "colors[0] = [0, 0, 0]  # black background\n",
    "false_colors = colors[labels]\n",
    "plt.imshow(false_colors)\n",
    "\n",
    "# Obtain centroids\n",
    "false_colors_centroid = false_colors.copy()\n",
    "for centroid in centroids:\n",
    "    cv2.drawMarker(false_colors_centroid, (int(centroid[0]), int(centroid[1])),\n",
    "                   color=(255, 255, 255), markerType=cv2.MARKER_CROSS)\n",
    "plt.imshow(false_colors_centroid)\n",
    "\n",
    "# Remove small objects\n",
    "MIN_AREA = 50\n",
    "false_colors_area_filtered = false_colors.copy()\n",
    "for i, centroid in enumerate(centroids[1:], start=1):\n",
    "    area = stats[i, 4]\n",
    "    if area > MIN_AREA:\n",
    "        cv2.drawMarker(false_colors_area_filtered, (int(centroid[0]), int(centroid[1])),\n",
    "                       color=(255, 255, 255), markerType=cv2.MARKER_CROSS)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img)\n",
    "plt.subplot(222)\n",
    "plt.imshow(hed)\n",
    "plt.subplot(223)\n",
    "plt.imshow(thresh)\n",
    "plt.subplot(224)\n",
    "plt.imshow(false_colors_area_filtered) \n",
    "plt.show()\n",
    "\n",
    "############################\n",
    "#Alternatively, We can also use regionprops from skimage to extract various parameters\n",
    "\n",
    "# regionprops function in skimage measure module calculates useful parameters for each object.\n",
    "from skimage import measure\n",
    "props = measure.regionprops_table(labels, intensity_image=img, \n",
    "                              properties=['label',\n",
    "                                          'area', 'equivalent_diameter',\n",
    "                                          'mean_intensity', 'solidity'])\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(props)\n",
    "\n",
    "#Filter by size\n",
    "#df = df[df.area > 5000]\n",
    "#df = df[df.area < 10000000000000000000000000000000000000000000000000000000000000000000000000000000]\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
